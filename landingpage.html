<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>CS 639: Intro to Computer Vision</title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	text-indent: -1.7em;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(55, 53, 47, 1);
}
.highlight-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.highlight-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.highlight-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.highlight-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.highlight-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.highlight-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.highlight-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.highlight-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.highlight-gray_background {
	background: rgba(241, 241, 239, 1);
}
.highlight-brown_background {
	background: rgba(244, 238, 238, 1);
}
.highlight-orange_background {
	background: rgba(251, 236, 221, 1);
}
.highlight-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.highlight-teal_background {
	background: rgba(237, 243, 236, 1);
}
.highlight-blue_background {
	background: rgba(231, 243, 248, 1);
}
.highlight-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.highlight-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.highlight-red_background {
	background: rgba(253, 235, 236, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.block-color-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.block-color-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.block-color-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.block-color-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.block-color-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.block-color-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.block-color-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.block-color-gray_background {
	background: rgba(241, 241, 239, 1);
}
.block-color-brown_background {
	background: rgba(244, 238, 238, 1);
}
.block-color-orange_background {
	background: rgba(251, 236, 221, 1);
}
.block-color-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.block-color-teal_background {
	background: rgba(237, 243, 236, 1);
}
.block-color-blue_background {
	background: rgba(231, 243, 248, 1);
}
.block-color-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.block-color-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.block-color-red_background {
	background: rgba(253, 235, 236, 1);
}
.select-value-color-pink { background-color: rgba(245, 224, 233, 1); }
.select-value-color-purple { background-color: rgba(232, 222, 238, 1); }
.select-value-color-green { background-color: rgba(219, 237, 219, 1); }
.select-value-color-gray { background-color: rgba(227, 226, 224, 1); }
.select-value-color-opaquegray { background-color: rgba(255, 255, 255, 0.0375); }
.select-value-color-orange { background-color: rgba(250, 222, 201, 1); }
.select-value-color-brown { background-color: rgba(238, 224, 218, 1); }
.select-value-color-red { background-color: rgba(255, 226, 221, 1); }
.select-value-color-yellow { background-color: rgba(253, 236, 200, 1); }
.select-value-color-blue { background-color: rgba(211, 229, 239, 1); }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="87c76186-be40-4077-b110-a034f55aadb5" class="page sans"><header><h1 class="page-title">CS 639: Intro to Computer Vision</h1></header><div class="page-body"><h1 id="9abbad88-8b7d-46b5-b2d4-76a24c5061d4" class="">Final Project: Unsupervised Continual Learning</h1><p id="4794352b-2c4e-46c6-81b9-5acce08717a8" class="">Jones Lin, Grant Ovsepyan, Christopher Gottwaldt, Michael Berkey</p><h2 id="e510e77d-9ebd-49e7-b675-f37e294dc4ff" class="">Motivation</h2><p id="688e02ac-aa2f-4243-a40a-94aabaa1452a" class="">    We wanted to create an unsupervised continual learning model that could maintain its image classification performance on prior datasets even after being trained on new datasets. Deep learning models have achieved great performance on various tasks including image classification, detection \cite{srivastava2021comparative}, segmentation \cite{hesamian2019deep}, etc. with applications in high-impact fields such as the medical field \cite{cai2020review}. Despite this progress, most of these models still require static training, which differs from human cognition systems \cite{kudithipudi2022biological} which can train in a more dynamic manner. When introducing new data, training a network on this entire dataset -- meaning using the new and old data -- is expensive and often infeasible due to limited computation resources as well as data privacy problems; This means that requiring model training to be static is very limiting. </p><p id="9a8e25f6-3b3e-4ecd-ace7-68536210d4b9" class="">    Under the static training strategy, models need to be trained on the whole dataset at one time or else they will &quot;forget&quot; what they have learned abruptly upon being provided with new data; This phenomenon is termed as &quot;catastrophic forgetting&quot; \cite{goodfellow2013empirical,mccloskey1989catastrophic}. For example, if we train a ResNet18 \cite{he2016deep} model, termed A, on the ImageNet dataset \cite{5206848}, and we then feed it novel data with new labeled categories to get another model named B, we find that the model B forgets the knowledge gleaned from the ImageNet dataset: i.e. the model&#x27;s performance on the ImageNet dataset drops significantly.</p><p id="931a0274-4ad7-4591-97b4-5f70c923b5b0" class="">    Previous works tried to address this catastrophic forgetting problem by replaying the previous data \cite{rebuffi2017icarl, rolnick2019experience}, adding a regularization term into the loss function \cite{lee2017overcoming, kirkpatrick2017overcoming}, and isolating important parameters \cite{mallya2018piggyback, mallya2018packnet}. The above methods all aim to prevent catastrophic forgetting during supervised learning. In our project, we consider a more strict situation in which we want to achieve continual learning under unsupervised learning. </p><p id="e7cdb224-c751-4cdf-9aa8-ff9b9bcb4d3e" class="">    Unsupervised learning is another method of training machine learning models where the model is not using labeled data. Supervised learning is useful in that it can be very accurate with less training data, but the downside is that this data has to be labeled accurately: a notoriously tedious process that can be minimized with the use of unsupervised learning models.</p><p id="c6cd9e32-9a7d-4dc1-b6a3-978f578f78d5" class="">     While being a useful method, supervised learning has trouble competing with unsupervised learning models. The SimSiam models \cite{chen2021exploring}, which take an unsupervised continual learning approach to their training, have demonstrated themselves to be very effective in classification tasks. SimSiam models take two randomly augmented views of the same image, process them through an encoder network, and then maximize the similarity between the outputs for the image augmentations\cite{chen2021exploring}. </p><p id="9c226683-1c0f-4b83-b594-f90d4da0f676" class="">    Even one of the most naïve SimSiam models, FINETUNE, outperforms virtually every supervised continual learning model save for DER when benchmarked on Split-CIFAR-10, Split-CIFAR-100, and Split Tiny-ImageNet. In <a href="https://openreview.net/pdf?id=9Hrka5PA7LW">this </a>paper, they list some metrics in which unsupervised continual learning models are able to outperform the supervised continual learning models \cite{madaan2021representational}. They demonstrate the greater performance in section 5.3 with notable findings such as: Demonstrated by higher CKA feature similarities and lower l2 distances, unsupervised continual learning models appear to be more robust to forgetting with more layers, unsupervised models are less prone to catastrophic forgetting when compared to their supervised counterparts, and the task loss has a flatter and smoother landscape.</p><p id="78dfa42b-f0e7-47b3-a5b2-cfaef8827fd5" class="">    The reason we want to solve this problem is because we would like to have a model that can learn from a variety of datasets without losing performance on previous datasets. This is important in getting closer to achieving a model that has uses outside of a very specialized use case while also minimizing both manual intervention and computational costs.</p><h2 id="18a14a56-1b8e-4b8b-baf4-9b55349e938e" class="">Approach</h2><p id="eed2ef10-5919-4ac6-967d-3c65a32fad6f" class="">    In our project, we wanted to mitigate catastrophic forgetting in self-supervised continual learning (SSL) using our own, novel approach; Our hope is that the deep learning models can remember what they have learned from their training on previous datasets. We are not the first to consider continual learning under unsupervised learning situations \cite{purushwalkam2022challenges, he2022unsupervised, munoz2019unsupervised}, but these attempts either utilize pseudo labels to train their models or contrast learning as a pretext task to achieve the goal. Since previous methods focus on how to achieve SSL via contrast learning, our methodology differs from them in that we use image reconstruction as a pretext task. More specifically, we use Masked Autoencoders (MAE) \cite{he2022masked} as our baseline, and we explored whether the existing continual learning techniques are able to be compatible with it, such as: Semantic Drift Compensation \cite{yu2020semantic}, the Nearest-Mean-of-Exemplars Classification \cite{rebuffi2017icarl}, etc. We hope this approach will enable the training of models that can adapt to new tasks without forgetting their prior knowledge.</p><p id="4ac116a7-c769-4876-8942-713d5a944b66" class="">    Before evaluating why the model is forgetting, we needed to find out the bounds. To accomplish this, we needed to train the whole dataset jointly with the SimSiam \cite{chen2021exploring} and mask MAE \cite{he2022masked} models. Following this process, we split the various benchmarks into multiple sub-datasets; We then split the 101 categories in the Caltech101 dataset into 10 small datasets which contain 10 or 11 classes per sub-dataset. Next, we trained the models on these ten sub-datasets sequentially, and we evaluated their performance on the previous dataset in order to determine the level of forgetting that is taking place (e.g. one model trained on the MAE and another trained on SimSiam). We compared their performance to conclude whether MAE is more effective in achieving continual learning. Finally, we combined the higher-performing method with existing continual learning techniques such as semantic drift compensation \cite{yu2020semantic} and the Nearest-Mean-of-Exemplars Classification \cite{rebuffi2017icarl}.</p><p id="4fe60eca-5356-4c95-b3fd-c67f74a3d1b6" class="">    As previously explained, SimSiam unsupervised continual learning models have shown lots of promise, so we tried testing along with MAE as well with two experiments: Using the base VIT model without pretraining the model, we evaluated the average accuracy and the forgetting of the models. The following two figures show that the MAE is better at both accurately classifying (represented by the first graph below) and preventing forgetting (represented by the second graph below). </p><p id="aeaacb37-c515-4aeb-a50d-9101d05a3051" class="">
</p><div id="20746fb2-262a-4fd0-8980-160a82ed0e58" class="column-list"><div id="8108ebb3-60c8-46b4-8cb5-58533ba37663" style="width:50%" class="column"><figure id="c7ccbf43-eaa3-41b4-8b87-5b07ecfd0e13" class="image"><a href="CS%20639%20Intro%20to%20Computer%20Vision%2087c76186be404077b110a034f55aadb5/Untitled.png"><img style="width:336px" src="CS%20639%20Intro%20to%20Computer%20Vision%2087c76186be404077b110a034f55aadb5/Untitled.png"/></a></figure><p id="727da4f2-24f3-4c7f-9a6a-fd2c4d2f824a" class="">Image Classification Accuracy of SimSiam vs MAE Methods</p></div><div id="79cf61dd-225a-49e9-a37e-289401cd01aa" style="width:50%" class="column"><figure id="8fef35f1-52f7-4344-928f-c4288cebbcfe" class="image"><a href="CS%20639%20Intro%20to%20Computer%20Vision%2087c76186be404077b110a034f55aadb5/Untitled%201.png"><img style="width:336px" src="CS%20639%20Intro%20to%20Computer%20Vision%2087c76186be404077b110a034f55aadb5/Untitled%201.png"/></a></figure><p id="5701edac-7533-454b-99a3-90eced1a5a44" class="">Image Classification Forgetting Rate of SimSiam vs MAE Methods</p></div></div><p id="28053d82-e982-49bd-a344-6aca3b48b463" class="">    Existing approaches largely consist of contrastive learning-based or stop-gradient-based methods that can address the problem; With the goal of preventing the model from forgetting, MAE is more stable in helping the model from succumbing to pattern collapsing. Due to this capability, MAE may bring better performance in the continual learning setting. (Refer to the mathematical proof below, which demonstrates the potential increased effectiveness of using MAE)</p><p id="e4b29af6-d240-44b2-a8dd-4a6632be573b" class="">When the MAE, f, falls into the collapsing, which means all inputs, x, are mapped into the same point, c: </p><p id="a0447d40-0ba5-4cbc-86af-622f850172ed" class=""><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>c</mi></mrow><annotation encoding="application/x-tex">f(x) = c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">c</span></span></span></span></span><span>﻿</span></span> where ∀x∈Ω, and Ω denotes the input images space. </p><p id="52ef6b91-1086-4d21-808d-d1f1962f95c5" class="">    In this scenario, the input images are masked images in the MAE setting \cite{he2022masked}. Therefore, the loss of MAE can be modeled as: </p><figure id="cd1c8010-8dea-4260-9576-96f3fad4ae73" class="image"><a href="CS%20639%20Intro%20to%20Computer%20Vision%2087c76186be404077b110a034f55aadb5/Untitled%202.png"><img style="width:336px" src="CS%20639%20Intro%20to%20Computer%20Vision%2087c76186be404077b110a034f55aadb5/Untitled%202.png"/></a></figure><p id="39dd5efd-a925-44bc-ad25-ebcd0277c8ce" class="">According to the Karush–Kuhn–Tucker condi›tions (KKT) conditions, there exists a solution c*<em> such that: </em></p><figure id="b0576e1f-b729-4522-8934-94a551140302" class="image"><a href="CS%20639%20Intro%20to%20Computer%20Vision%2087c76186be404077b110a034f55aadb5/Untitled%203.png"><img style="width:144px" src="CS%20639%20Intro%20to%20Computer%20Vision%2087c76186be404077b110a034f55aadb5/Untitled%203.png"/></a></figure><p id="372d9e51-0860-487e-b65b-7d70b0947150" class="">Therefore, E[c∗]=E[y]</p><p id="ec53260f-55c9-438a-a25f-b3b287a42f03" class="">Since our objective is minimizing </p><figure id="fb89af44-0a29-49cc-a53f-1f40643c327f" class="image"><a href="CS%20639%20Intro%20to%20Computer%20Vision%2087c76186be404077b110a034f55aadb5/Untitled%204.png"><img style="width:108px" src="CS%20639%20Intro%20to%20Computer%20Vision%2087c76186be404077b110a034f55aadb5/Untitled%204.png"/></a></figure><p id="50c588b8-d0fd-4ede-aa6d-900cd375fdc2" class=""><em>so we can get the lower boundary of the </em></p><figure id="2bd3f878-5bf8-424b-8bfa-73f4baf67ed3" class="image"><a href="CS%20639%20Intro%20to%20Computer%20Vision%2087c76186be404077b110a034f55aadb5/Untitled%205.png"><img style="width:1246px" src="CS%20639%20Intro%20to%20Computer%20Vision%2087c76186be404077b110a034f55aadb5/Untitled%205.png"/></a></figure><p id="e2f00c1b-1d7e-4616-b7e8-34c40408d037" class="">where the σ denotes the variance and the y is the ground truth (original image). If the original image has a lot of variance, the lower boundary is also high. Thus, it&#x27;s not easy to fall into pattern collapsing.</p><p id="40dbf3fb-ad9c-4859-b207-7bbb92898230" class="">Once f, the mask autoencoder (MAE), falls into pattern collapsing, then all inputs x are mapped into the same point c, such that: f(x)=c where x denotes the input image space. Therefore, the loss of the MAE can be represented by: </p><div id="d816d96e-e0ec-4847-90e4-c0a8489c6b30" class="column-list"><div id="c47f063e-f5b2-43b0-a70e-62b3ea90b93a" style="width:37.5%" class="column"><figure id="aaf0e00b-89cb-432a-9728-ebf5bfa902d6" class="image"><a href="CS%20639%20Intro%20to%20Computer%20Vision%2087c76186be404077b110a034f55aadb5/Untitled%206.png"><img style="width:259px" src="CS%20639%20Intro%20to%20Computer%20Vision%2087c76186be404077b110a034f55aadb5/Untitled%206.png"/></a></figure></div><div id="994713b3-3ea8-4e2b-99e0-5c4b46fc0cd8" style="width:62.5%" class="column"><figure id="74f52fbf-d360-493f-a8a3-471d65e0f902" class="image"><a href="CS%20639%20Intro%20to%20Computer%20Vision%2087c76186be404077b110a034f55aadb5/Untitled%207.png"><img style="width:236px" src="CS%20639%20Intro%20to%20Computer%20Vision%2087c76186be404077b110a034f55aadb5/Untitled%207.png"/></a></figure></div></div><p id="d5de70e3-1d9b-4812-aacc-492461f89735" class="">In trying to solve this older problem with a newer method, we hope it may inspire the community in the future to build off of this.</p><p id="a635b779-3745-4d8d-89c8-e862fcbfbb04" class="">We set up two metrics to evaluate the performance of our solution. One us used to measure the accuracy (where a larger number is better:
Let <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mi>τ</mi></msub><mo separator="true">,</mo><mi>i</mi></mrow><annotation encoding="application/x-tex">a_\tau, i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.85396em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.1132em;">τ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">i</span></span></span></span></span><span>﻿</span></span> denote the test accuracy of task <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span></span></span></span></span><span>﻿</span></span> after learning task <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>τ</mi></msub></mrow><annotation encoding="application/x-tex">T_\tau </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.1132em;">τ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> using a KNN on frozen pre-trained representations on task <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>τ</mi></msub></mrow><annotation encoding="application/x-tex">T_\tau</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.1132em;">τ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span></p><p id="87185395-4b11-4573-90bd-080e084e4677" class="">Average Accuracy: </p><figure id="8d178a3d-f75e-4b18-bfce-de55255d9187" class="image"><a href="CS%20639%20Intro%20to%20Computer%20Vision%2087c76186be404077b110a034f55aadb5/Untitled%208.png"><img style="width:192px" src="CS%20639%20Intro%20to%20Computer%20Vision%2087c76186be404077b110a034f55aadb5/Untitled%208.png"/></a></figure><p id="346dc3b6-d2e7-46a7-8565-6e2f4993bc3c" class="">The other metric is used to evaluate the rate of forgetting (where a lower number is better).</p><p id="fb1e18d6-5acd-4b58-8f7c-efe49a9b07dd" class="">Average Forgetting: </p><figure id="c7360a37-c189-4af3-9c3c-97703f307b39" class="image"><a href="CS%20639%20Intro%20to%20Computer%20Vision%2087c76186be404077b110a034f55aadb5/Untitled%209.png"><img style="width:384px" src="CS%20639%20Intro%20to%20Computer%20Vision%2087c76186be404077b110a034f55aadb5/Untitled%209.png"/></a></figure><h2 id="c86b726f-d72e-4e0a-9403-dd8adbb81716" class="">Implementation</h2><p id="09119634-dfe7-47df-bf0d-a51098ad18de" class="">    Our model works by using 2 images, with the first having a 30% chance of being from the previous dataset, and the 2nd always being from the current dataset. Then these images are mixed together, passed through a mask function which removes some of the image data, and they are then passed through an encoder and a decoder. The results are then used to determine the loss of the model, but we calculate our loss a little bit differently as explained in the diagram below:</p><p id="9dd0ff93-347b-4d29-8f55-4d8b8fad4f2d" class="">
</p><figure id="ae8f24c5-c7ac-44da-bf22-1233ae6fb63f" class="image"><a href="CS%20639%20Intro%20to%20Computer%20Vision%2087c76186be404077b110a034f55aadb5/Untitled%2010.png"><img style="width:864px" src="CS%20639%20Intro%20to%20Computer%20Vision%2087c76186be404077b110a034f55aadb5/Untitled%2010.png"/></a></figure><p id="b4d50e84-a413-42be-82c1-c175198724e6" class="">    A mathematical equation representing this process can be seen below, where:</p><p id="7fe5a449-6a26-4887-96f8-40241bb21fdc" class=""><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>I</mi><mn>1</mn></msub><mo>=</mo><mi>I</mi><mi>m</mi><mi>a</mi><mi>g</mi><mi>e</mi><mn>1</mn><mo separator="true">,</mo><msub><mi>I</mi><mn>2</mn></msub><mo>=</mo><mi>I</mi><mi>m</mi><mi>a</mi><mi>g</mi><mi>e</mi><mn>2</mn><mo separator="true">,</mo><msub><mi>I</mi><mi>M</mi></msub><mo>=</mo><msub><mi>I</mi><mn>1</mn></msub><mo>+</mo><msub><mi>I</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">I_1 = Image 1, I_2 = Image  2, I_M = I_1 + I_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal">ma</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">e</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal">ma</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">e</span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span></p><p id="f14cac00-3295-4167-af0a-b2de5ff0c239" class=""><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>I</mi><mo>~</mo></mover><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">Ĩ_1 </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0701899999999998em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9201899999999998em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span></span><span style="top:-3.6023300000000003em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.13889em;"><span class="mord">~</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> = the outputted Image1, <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>I</mi><mo>~</mo></mover><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">Ĩ_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0701899999999998em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9201899999999998em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span></span><span style="top:-3.6023300000000003em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.13889em;"><span class="mord">~</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> = the outputted Image2, and <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>I</mi><mo>~</mo></mover><mi>m</mi></msub></mrow><annotation encoding="application/x-tex">Ĩ_m </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0701899999999998em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9201899999999998em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span></span><span style="top:-3.6023300000000003em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.13889em;"><span class="mord">~</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> is the outputted mixed image</p><p id="25fd42fb-a4e2-481d-b763-e6e07c4f9b00" class=""><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>I</mi><mo>~</mo></mover><mi>x</mi></msub></mrow><annotation encoding="application/x-tex">Ĩ_x </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0701899999999998em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9201899999999998em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span></span><span style="top:-3.6023300000000003em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.13889em;"><span class="mord">~</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> is the combination of Image1 and Image2; This image is used to compute our loss</p><figure id="a76a895f-9455-4fc4-b8df-7eeb248a450d" class="image"><a href="CS%20639%20Intro%20to%20Computer%20Vision%2087c76186be404077b110a034f55aadb5/Untitled%2011.png"><img style="width:1102px" src="CS%20639%20Intro%20to%20Computer%20Vision%2087c76186be404077b110a034f55aadb5/Untitled%2011.png"/></a></figure><p id="7b4d0398-70d8-4287-ac6a-7c9613fb44e9" class="">
</p><h2 id="b603ca89-6021-4a47-9f21-a8ffe2ccaaff" class="">Results</h2><p id="47b2d699-2938-4f22-9efa-2f02ea43fa9f" class="">    We tested our models on the CUB200 \cite{wah_branson_welinder_perona_belongie_2022} and TinyImageNet datasets, and we compared their performance against the existing SimSiam and MAE models.</p><p id="db3f0738-1133-4276-ad36-84c5120d7bfb" class="">    We tried various combinations of using a buffer and norm and the resulting accuracy and forgetting rates are included below. </p><h3 id="61e74a07-10b5-4a75-8df8-5deef8e126f1" class="">CUB Dataset Performance Comparison (while using a buffer):</h3><figure id="813a3f7e-ac93-408f-9c1f-c30a32231961" class="image"><a href="CS%20639%20Intro%20to%20Computer%20Vision%2087c76186be404077b110a034f55aadb5/Untitled%2012.png"><img style="width:576px" src="CS%20639%20Intro%20to%20Computer%20Vision%2087c76186be404077b110a034f55aadb5/Untitled%2012.png"/></a></figure><figure id="fa0d08d8-7e55-4008-b9aa-8afe8031ad16" class="image"><a href="CS%20639%20Intro%20to%20Computer%20Vision%2087c76186be404077b110a034f55aadb5/Untitled%2013.png"><img style="width:576px" src="CS%20639%20Intro%20to%20Computer%20Vision%2087c76186be404077b110a034f55aadb5/Untitled%2013.png"/></a></figure><p id="280f4696-defa-4bbd-8c15-4c443eb521c8" class="">
</p><h3 id="1683fbe0-946a-401a-8db1-3b6b533bb58d" class="">CUB Dataset Performance (without using a buffer):</h3><figure id="e9ac1ec9-1ff5-46f4-868f-e1c5f29f11c5" class="image"><a href="CS%20639%20Intro%20to%20Computer%20Vision%2087c76186be404077b110a034f55aadb5/Untitled%2014.png"><img style="width:558px" src="CS%20639%20Intro%20to%20Computer%20Vision%2087c76186be404077b110a034f55aadb5/Untitled%2014.png"/></a></figure><p id="edcb9210-9b50-406f-b03c-c82364998029" class="">
</p><h3 id="b5242c9d-50f4-4a5f-a409-bac447ad9d1b" class="">TinyImageNet Dataset Performance (while using a buffer):</h3><figure id="276b3875-d73d-4e5f-9d29-64b8c3127c11" class="image"><a href="CS%20639%20Intro%20to%20Computer%20Vision%2087c76186be404077b110a034f55aadb5/Untitled%2015.png"><img style="width:554px" src="CS%20639%20Intro%20to%20Computer%20Vision%2087c76186be404077b110a034f55aadb5/Untitled%2015.png"/></a></figure><p id="65f1c4cc-247b-4527-9280-8c8570e6074d" class="">
</p><h3 id="2676619f-afea-409b-90b8-66d9cbcaa5f0" class="">TinyImageNet Dataset Performance (without using a buffer):</h3><figure id="4d350bff-1728-4d12-9095-ca6235a48c4f" class="image"><a href="CS%20639%20Intro%20to%20Computer%20Vision%2087c76186be404077b110a034f55aadb5/Untitled%2016.png"><img style="width:551px" src="CS%20639%20Intro%20to%20Computer%20Vision%2087c76186be404077b110a034f55aadb5/Untitled%2016.png"/></a></figure><p id="d4d35b31-25b6-4ca7-a109-34b6307861bb" class="">
</p><h2 id="e8df9df3-29da-481e-82fb-7a8422b6975c" class="">Understanding the Results</h2><p id="41a0e597-ac67-4eae-8762-e68a5be6ed12" class="">    Accuracy is the rate at which the model can correctly classify an image, and forgetting is the rate at which a model’s performance decreases on a past dataset; Our numbers are represented as a percent (eg: 53.94 = 53.94% accurate) and therefore the highest numbers are most desirable. A positive forgetting rate means that the model is actively forgetting the ability to classify the past data (which we are trying to prevent from happening), and a negative forgetting rate means that the model is actually still getting better at classifying the past data (which we want to have happen).  Therefore we want our accuracy to be high, and the forgetting rate to be low.</p><p id="97c34133-f885-4782-b95f-4bf07850c1e3" class="">    Our goal was to create a model that was resistant to forgetting, and the results demonstrate that our did a decent job of this with it outperforming the existing methods in quite a few instances.</p><p id="5a0425a0-c42a-493e-b3c5-dd5a7a9b82e1" class="">
</p><h2 id="92cc6bcd-4ae5-4326-9a59-8aeea17a18be" class="">Difficulties</h2><p id="5feb5bc4-8a91-4b1b-b24e-c38ba4d0366c" class="">    Although the project went well overall, there were a few challenges that arose along the way. When we first started the project, we wanted to take a slightly different approach to solving our problem; Originally we were intending on using MoCo v3 models, but we changed our approach to the current methods soon after we set out on the project. <strong></strong></p><p id="b3994361-8b6b-41c3-881c-a5bd731269ae" class="">    Most of our difficulties were actually in the web development portion of the project because of a lack of prior experience in the field, so we started out with raw HTML CSS (in hindsight this was not a good decision) and changed our approach a few times. Eventually we switched to using GitHub pages. We had some other small difficulties such as getting the mathematical equations to render, and we had a busy schedule with half of us applying to grad school and the others having a heavy course load. </p><p id="b834bbfc-adf1-4b74-8625-2a8ecdbd2f16" class="">
</p><p id="8ff40130-88d7-40ba-8127-0d83fa1f1b13" class="">
</p></div></article></body></html>
